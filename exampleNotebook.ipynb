{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7XhFKLT9Z3X"
      },
      "source": [
        "import numpy as np\n",
        "import data_io\n",
        "from data_preprocessing import *\n",
        "from implementations import *\n",
        "import validation"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeFvS4uBISjd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQtukcZPITUH"
      },
      "source": [
        "DATA_FILE_PREFIX = '/content/drive/My Drive/mlproject1_higgs_data/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9QxL8h891WE"
      },
      "source": [
        "y, x, ids, cols = data_io.load_csv_data(f'{DATA_FILE_PREFIX}train.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCCEpWJOvlZg"
      },
      "source": [
        "# Make it easier to access columns by their name\n",
        "col_to_index_mapping = {col_name: index - 2 for index, col_name in enumerate(cols) if index >= 2}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJ9Mn729JW8"
      },
      "source": [
        "col_to_index_mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-WoMmCrX6_Z"
      },
      "source": [
        "#pred = map_values(np.random.randint(0, 2, y.size), {0: -1, 1: 1})\n",
        "pred = np.array([-1] * y.size)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqaLcbS1YAt0"
      },
      "source": [
        "import metrics\n",
        "# Tests metrics (fbeta_score, precision and recall might return \"RuntimeWarning: invalid value encountered in long_scalars\"\n",
        "#     which functions take care of (these are nan cases) by returning 0)\n",
        "print('Acc:', metrics.accuracy(y, pred))\n",
        "print('Fbeta:', metrics.fbeta_score(y, pred))\n",
        "print('Precision:', metrics.precision(y, pred))\n",
        "print('Recall:', metrics.recall(y, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqIpNoBlbLx"
      },
      "source": [
        "def train_model(y, x):\n",
        "  #w, _ = least_squares_SGD(y, x, np.zeros((x.shape[1],)), 100, gamma=0.01)\n",
        "  w, loss = least_squares(y, x)\n",
        "  def predict(features):\n",
        "    result = features @ w\n",
        "    result[np.where(result < 0)] = -1\n",
        "    result[np.where(result >= 0)] = 1\n",
        "    return result\n",
        "  return predict"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJTE9otJoIVA"
      },
      "source": [
        "tx = np.copy(x) # Recommended to copy x so it doesn't change\n",
        "\n",
        "missing_values = tx == -999.\n",
        "print(np.sum(np.sum(missing_values, axis = 1) < 6)) # Checking how many rows with less than 6 fields missing is there\n",
        "tx = apply_transformation(tx, [col_to_index_mapping[key] for key in col_to_index_mapping if 'PRI_jet_num' not in key], standardize)\n",
        "tx = nullify_missing_values(tx, missing_values) # standardize and normalize may change value of fields from default missing values, so it uses matrix calculated before applying transformations\n",
        "tx = apply_transformation(tx, [col_to_index_mapping['PRI_jet_num']], one_hot) # recommended to use function that map input to output of same dimensions first (standardize, normalize, etc.) and then functions such as one_hot\n",
        "tx = prepend_bias_column(tx)\n",
        "\n",
        "print(tx) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji5b1oXKpXpe"
      },
      "source": [
        "_ = validation.cross_validation(y, tx, train_model, 10, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of MLHiggs_sin_cos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFPCqsatcmRU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import data_io\n",
        "import data_preprocessing\n",
        "from implementations import *\n",
        "import validation\n",
        "import attribute_selection\n",
        "import evaluators\n",
        "import metrics\n",
        "\n",
        "# Autoreload modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRl8fmwZdvp4",
        "outputId": "df20e260-ec2f-46f4-a216-6341180f9755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_FILE_PREFIX = '/content/drive/My Drive/mlproject1_higgs_data/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7x1A5HTd1Md"
      },
      "source": [
        "y_train, x_train, _, cols = data_io.load_csv_data(f'{DATA_FILE_PREFIX}train.csv')\n",
        "_, x_test, ids_test, cols_train = data_io.load_csv_data(f'{DATA_FILE_PREFIX}test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQzHQa0GdxmT"
      },
      "source": [
        "col_to_index_mapping = {col_name: index - 2 for index, col_name in enumerate(cols) if index >= 2}\n",
        "y_train = (y_train + 1) // 2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9OwvjhveW0E"
      },
      "source": [
        "def transformation_pipeline_base(x, col_to_index_mapping=col_to_index_mapping):\n",
        "    tx = np.copy(x) # Recommended to copy x so it doesn't change\n",
        "    tx[tx == -999.] = np.nan\n",
        "    tx = data_preprocessing.apply_transformation(\n",
        "        tx,\n",
        "        [col_to_index_mapping[key] for key in col_to_index_mapping if 'PRI_jet_num' not in key],\n",
        "        data_preprocessing.standardize_with_nans,\n",
        "    )\n",
        "    # standardize and normalize may change value of fields from default missing values, so it uses matrix calculated before applying transformations\n",
        "    tx = data_preprocessing.nullify_missing_values(tx, np.isnan(tx)) \n",
        "    # onehot for categorical and drop one level\n",
        "    tx, col_to_index_mapping_upd = data_preprocessing.one_hot_transformation(tx, 'PRI_jet_num', col_to_index_mapping)\n",
        "    tx = tx[:, :-1]\n",
        "    # add bias\n",
        "    tx = data_preprocessing.prepend_bias_column(tx)\n",
        "    return tx\n",
        "\n",
        "def transformation_pipeline_median(x, col_to_index_mapping=col_to_index_mapping):\n",
        "    tx = np.copy(x) # Recommended to copy x so it doesn't change\n",
        "    tx[tx == -999.] = np.nan\n",
        "    tx = data_preprocessing.apply_transformation(\n",
        "        tx,\n",
        "        [col_to_index_mapping[key] for key in col_to_index_mapping if 'PRI_jet_num' not in key],\n",
        "        data_preprocessing.standardize_with_nans,\n",
        "    )\n",
        "    # standardize and normalize may change value of fields from default missing values, so it uses matrix calculated before applying transformations\n",
        "    tx = data_preprocessing.median_missing_values(tx, np.isnan(tx)) \n",
        "    # onehot for categorical and drop one level\n",
        "    tx, col_to_index_mapping_upd = data_preprocessing.one_hot_transformation(tx, 'PRI_jet_num', col_to_index_mapping)\n",
        "    tx = tx[:, :-1]\n",
        "\n",
        "    sins = np.sin(tx)\n",
        "    coses = np.cos(tx)\n",
        "    #polys = data_preprocessing.build_poly(tx, list(range(tx.shape[1])), [2])\n",
        "    tx = np.concatenate((tx, sins, coses), axis=1)\n",
        "    \n",
        "    # add bias\n",
        "    tx = data_preprocessing.prepend_bias_column(tx)\n",
        "    return tx"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J19pfqD6evUs"
      },
      "source": [
        "tx_train = transformation_pipeline_median(x_train)\n",
        "\n",
        "first_selection_attr = [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96]\n",
        "tx_train = tx_train[:, first_selection_attr]\n",
        "tx_train = tx_train[:, [0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 27, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNVAcSk0pLNC"
      },
      "source": [
        "import operator\n",
        "\n",
        "def tune_lambda(y, x, grid, seed=42):\n",
        "    w_init = np.zeros(x.shape[1])\n",
        "    res = {}\n",
        "    for lambda_ in grid:\n",
        "        np.random.seed(seed)\n",
        "        train_model = lambda y_, x_: make_predictor(reg_logistic_regression_sgd(\n",
        "            y_, x_, lambda_, w_init, 5, 1000, 0.5,\n",
        "        )[0])\n",
        "        res[lambda_] = validation.cross_validation(y, x, train_model, 5)[0].mean()\n",
        "        print(f\"{lambda_}: {res[lambda_]:.4f}\")\n",
        "    return max(res.items(), key=operator.itemgetter(1))[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8X9uAUXfLo9"
      },
      "source": [
        "def make_predictor(w):\n",
        "  def foo(features):\n",
        "    return (features @ w > 0).astype(int)\n",
        "  return foo"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDJkvPsNfz20"
      },
      "source": [
        "def train_model(y, x):\n",
        "  w_init = np.zeros(x.shape[1])\n",
        "  lambda_ = 1e-5\n",
        "  return make_predictor(reg_logistic_regression_sgd(\n",
        "      y, x, lambda_, w_init, 5, 1000, 0.5)[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUXiHyVDgW_X",
        "outputId": "2d9ac622-fb58-4ccb-bad0-5eec4a4a82e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "_ = validation.cross_validation(y_train, tx_train, train_model, 10, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ 10-fold cross validation results ------\n",
            "    Accuracy: avg 0.8156, max 0.81852, min 0.81212, stddev 0.002433\n",
            "    Fbeta score: avg 0.72166, max 0.73235, min 0.7091, stddev 0.0071623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9JiQecwdFSF",
        "outputId": "2875c9dd-1e42-48cd-c7aa-e9fa845915b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "tune_lambda(y_train, tx_train, [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: 0.3429\n",
            "0.1: 0.7464\n",
            "0.01: 0.7926\n",
            "0.001: 0.8122\n",
            "0.0001: 0.8173\n",
            "1e-05: 0.8180\n",
            "1e-06: 0.8180\n",
            "1e-07: 0.8180\n",
            "1e-08: 0.8179\n",
            "1e-09: 0.8179\n",
            "1e-10: 0.8179\n",
            "1e-11: 0.8179\n",
            "1e-12: 0.8179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQEcT2CigkhK",
        "outputId": "2d56c5ac-827c-4ddd-f030-68ff6efef1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "attribute_selection.backward_attribute_selector(\n",
        "    y_train, \n",
        "    tx_train, \n",
        "    evaluators.cross_validation_mean_acc_evaluator(train_model),\n",
        "    20,\n",
        "    verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 96: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816472)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 95: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816076)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 94: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.81616)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 93: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.81628)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 92: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816204)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 91: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815888)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 90: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815732)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 89: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815844)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 88: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815968)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 87: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816172)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 86: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.81604)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 85: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815936)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 84: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815892)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 83: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816144)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 82: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816476)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 81: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.815988)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 80: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816132)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 79: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816268)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 78: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816168)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 77: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816288)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 76: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816164)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 75: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816292)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 74: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816296)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 73: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.8162)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 72: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816536)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 71: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816344)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 70: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816724)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 69: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816496)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 68: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816308)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 67: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816376)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 66: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816384)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 65: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816332)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 64: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816292)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 63: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.816276)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 62: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.81638)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 61: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.81636)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 60: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.816424)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 59: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 93, 94, 95, 96 (score 0.816528)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 58: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 93, 94, 95, 96 (score 0.816624)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 57: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 93, 94, 95, 96 (score 0.816368)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 56: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96 (score 0.81642)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 55: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96 (score 0.816328)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK3xHoQvO87W"
      },
      "source": [
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 96: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816472)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 95: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816076)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 94: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.81616)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 93: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.81628)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 92: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816204)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 91: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815888)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 90: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815732)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 89: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815844)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 88: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815968)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 87: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.816172)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 86: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.81604)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 85: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815936)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 84: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96 (score 0.815892)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 83: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816144)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 82: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816476)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 81: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.815988)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 80: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816132)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 79: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816268)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 78: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816168)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 77: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816288)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 76: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816164)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 75: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816292)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 74: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816296)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 73: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.8162)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 72: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96 (score 0.816536)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 71: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816344)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 70: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816724)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 69: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816496)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 68: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816308)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 67: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816376)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 66: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816384)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 65: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816332)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 64: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 89, 91, 93, 94, 95, 96 (score 0.816292)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 63: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.816276)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 62: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 20, 22, 25, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.81638)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 61: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 28, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.81636)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 60: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 86, 87, 88, 91, 93, 94, 95, 96 (score 0.816424)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 59: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 93, 94, 95, 96 (score 0.816528)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 58: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 93, 94, 95, 96 (score 0.816624)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 57: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 93, 94, 95, 96 (score 0.816368)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 56: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96 (score 0.81642)\n",
        " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 55: 0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96 (score 0.816328)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMRAznTYQXp5",
        "outputId": "ffcbfe22-ec79-4b88-b3ab-3ded6ec4fc11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "attribute_selection.backward_attribute_selector(\n",
        "    y_train, \n",
        "    tx_train, \n",
        "    evaluators.cross_validation_mean_acc_evaluator(train_model),\n",
        "    20,\n",
        "    verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 54: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816288)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 53: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816396)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 52: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816316)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 51: 0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816144)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 50: 0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816568)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 49: 0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816304)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 48: 0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.81654)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 47: 0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816732)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 46: 0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816772)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 45: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816336)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 44: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.8165)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 43: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816676)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 42: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 27, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816332)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 41: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 27, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816552)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 40: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.81628)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 39: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 23, 24, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816252)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 38: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 18, 19, 20, 23, 24, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816168)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 37: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 18, 19, 20, 23, 24, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816324)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 36: 0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 19, 20, 23, 24, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816336)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 35: 0, 1, 2, 3, 4, 6, 7, 9, 12, 13, 19, 20, 23, 24, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816032)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 34: 0, 1, 2, 3, 4, 6, 7, 9, 12, 13, 19, 20, 23, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54 (score 0.816308)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 33: 0, 1, 2, 3, 4, 6, 7, 9, 12, 13, 19, 20, 23, 25, 27, 31, 33, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.81598)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 32: 0, 1, 2, 3, 4, 6, 7, 9, 12, 13, 19, 20, 23, 25, 27, 31, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.815964)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 31: 1, 2, 3, 4, 6, 7, 9, 12, 13, 19, 20, 23, 25, 27, 31, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.8158)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 30: 1, 2, 3, 4, 6, 7, 9, 12, 13, 19, 20, 23, 27, 31, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.815596)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 29: 1, 2, 3, 4, 6, 7, 9, 13, 19, 20, 23, 27, 31, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.815288)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 28: 1, 2, 3, 4, 6, 7, 9, 13, 19, 20, 23, 27, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.815308)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 27: 1, 2, 3, 4, 6, 7, 9, 13, 19, 20, 23, 27, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.815024)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 26: 2, 3, 4, 6, 7, 9, 13, 19, 20, 23, 27, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.8148)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 25: 2, 3, 4, 6, 7, 9, 13, 19, 20, 27, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.814368)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 24: 3, 4, 6, 7, 9, 13, 19, 20, 27, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.81368)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 23: 3, 4, 6, 7, 9, 13, 19, 20, 27, 37, 38, 39, 40, 42, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.813488)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 22: 3, 4, 6, 7, 9, 19, 20, 27, 37, 38, 39, 40, 42, 45, 46, 48, 49, 50, 51, 52, 53, 54 (score 0.813124)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 21: 3, 4, 6, 7, 9, 19, 20, 27, 37, 38, 39, 40, 42, 45, 46, 48, 50, 51, 52, 53, 54 (score 0.812608)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 20: 3, 4, 6, 9, 19, 20, 27, 37, 38, 39, 40, 42, 45, 46, 48, 50, 51, 52, 53, 54 (score 0.81236)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 6, 9, 19, 20, 27, 37, 38, 39, 40, 42, 45, 46, 48, 50, 51, 52, 53, 54]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQupGajn1FBN",
        "outputId": "77aff996-5711-4594-bbbf-f5b58b0d5933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "tx_train_sub = tx_train[:, [3, 4, 6, 9, 19, 20, 27, 37, 38, 39, 40, 42, 45, 46, 48, 50, 51, 52, 53, 54]]\n",
        "\n",
        "attribute_selection.backward_attribute_selector(\n",
        "    y_train, \n",
        "    tx_train_sub, \n",
        "    evaluators.cross_validation_mean_acc_evaluator(train_model),\n",
        "    1,\n",
        "    verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 19: 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 (score 0.812068)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 18: 0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 (score 0.811316)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 17: 0, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19 (score 0.810528)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 16: 0, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19 (score 0.8097)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 15: 0, 2, 3, 4, 5, 7, 9, 11, 12, 14, 15, 16, 17, 18, 19 (score 0.809308)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 14: 0, 2, 3, 4, 5, 7, 9, 11, 12, 14, 15, 17, 18, 19 (score 0.80796)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 13: 0, 2, 3, 4, 5, 7, 9, 12, 14, 15, 17, 18, 19 (score 0.806528)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 12: 0, 2, 3, 4, 5, 7, 9, 12, 15, 17, 18, 19 (score 0.80502)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 11: 0, 3, 4, 5, 7, 9, 12, 15, 17, 18, 19 (score 0.80218)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 10: 0, 3, 4, 5, 7, 9, 12, 15, 17, 19 (score 0.79976)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 9: 0, 4, 5, 7, 9, 12, 15, 17, 19 (score 0.796844)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 8: 4, 5, 7, 9, 12, 15, 17, 19 (score 0.794212)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 7: 4, 5, 7, 12, 15, 17, 19 (score 0.791232)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 6: 4, 5, 7, 15, 17, 19 (score 0.786356)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 5: 4, 5, 7, 15, 17 (score 0.779152)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 4: 4, 5, 7, 17 (score 0.75672)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 3: 4, 5, 17 (score 0.745368)\n",
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 2: 5, 17 (score 0.694692)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/metrics.py:58: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  return true_positive_count / (true_positive_count + false_positive_count)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " --- BACKWARD ATTRIBUTE SELECTION: Best attribute indexes for size 1: 5 (score 0.66678)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnfLdL7cf_2h"
      },
      "source": [
        "def build_pairwise_plus(x, column_idx):\n",
        "    \"\"\"build pairwise multiplyed features x\"\"\"\n",
        "    if x.ndim == 1:\n",
        "        x = x[:, np.newaxis]\n",
        "        \n",
        "    columns = np.copy(x[:, column_idx])\n",
        "    pairwise = []\n",
        "    for i in range(columns.shape[1] - 1):\n",
        "        for j in range(i + 1, columns.shape[1] - 1):\n",
        "            pairwise.append(columns[:, i] + columns[:, j])\n",
        "    pairwise = np.array(pairwise).T\n",
        "    return np.concatenate([np.copy(x), pairwise], 1)\n",
        "\n",
        "def transformation_pipeline_median_selected(x, col_to_index_mapping=col_to_index_mapping):\n",
        "    tx = np.copy(x) # Recommended to copy x so it doesn't change\n",
        "    tx[tx == -999.] = np.nan\n",
        "    tx = data_preprocessing.apply_transformation(\n",
        "        tx,\n",
        "        [col_to_index_mapping[key] for key in col_to_index_mapping if 'PRI_jet_num' not in key],\n",
        "        data_preprocessing.standardize_with_nans,\n",
        "    )\n",
        "    # standardize and normalize may change value of fields from default missing values, so it uses matrix calculated before applying transformations\n",
        "    tx = data_preprocessing.median_missing_values(tx, np.isnan(tx)) \n",
        "    # onehot for categorical and drop one level\n",
        "    tx, col_to_index_mapping_upd = data_preprocessing.one_hot_transformation(tx, 'PRI_jet_num', col_to_index_mapping)\n",
        "    tx = tx[:, :-1]\n",
        "\n",
        "    sins = np.sin(tx)\n",
        "    coses = np.cos(tx)\n",
        "    #polys = data_preprocessing.build_poly(tx, list(range(tx.shape[1])), [2])\n",
        "    tx = np.concatenate((tx, sins, coses), axis=1)\n",
        "    \n",
        "    # add bias\n",
        "    tx = data_preprocessing.prepend_bias_column(tx)\n",
        "    first_selection_attr = [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96]\n",
        "    tx = tx[:, first_selection_attr]\n",
        "    tx = tx[:, [0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 27, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]]\n",
        "\n",
        "    return tx\n",
        "\n",
        "def transformation_pipeline_median_selected_pairwise(x, col_to_index_mapping=col_to_index_mapping):\n",
        "    tx = np.copy(x) # Recommended to copy x so it doesn't change\n",
        "    tx[tx == -999.] = np.nan\n",
        "    tx = data_preprocessing.apply_transformation(\n",
        "        tx,\n",
        "        [col_to_index_mapping[key] for key in col_to_index_mapping if 'PRI_jet_num' not in key],\n",
        "        data_preprocessing.standardize_with_nans,\n",
        "    )\n",
        "    # standardize and normalize may change value of fields from default missing values, so it uses matrix calculated before applying transformations\n",
        "    tx = data_preprocessing.median_missing_values(tx, np.isnan(tx)) \n",
        "    # onehot for categorical and drop one level\n",
        "    tx, col_to_index_mapping_upd = data_preprocessing.one_hot_transformation(tx, 'PRI_jet_num', col_to_index_mapping)\n",
        "    tx = tx[:, :-1]\n",
        "\n",
        "    sins = np.sin(tx)\n",
        "    coses = np.cos(tx)\n",
        "    #polys = data_preprocessing.build_poly(tx, list(range(tx.shape[1])), [2])\n",
        "    tx = np.concatenate((tx, sins, coses), axis=1)\n",
        "    \n",
        "    # add bias\n",
        "    tx = data_preprocessing.prepend_bias_column(tx)\n",
        "    first_selection_attr = [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 20, 22, 25, 30, 31, 33, 34, 35, 36, 40, 41, 42, 44, 45, 47, 49, 50, 52, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 79, 81, 82, 87, 88, 91, 94, 95, 96]\n",
        "    tx = tx[:, first_selection_attr]\n",
        "    tx = tx[:, [1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 27, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]]\n",
        "\n",
        "    tx = data_preprocessing.build_pairwise(tx, list(range(tx.shape[1])))\n",
        "\n",
        "    tx = data_preprocessing.prepend_bias_column(tx)\n",
        "    \n",
        "    return tx"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EP6nsaPghYg"
      },
      "source": [
        "tx_train_2 = transformation_pipeline_median_selected_pairwise(x_train)\n",
        "\n",
        "'''\n",
        "tx_train_2 = tx_train_2[:, [  4,   6,   7,   9,  10,  11,  13,  15,  16,  18,  19,  21,  28,\n",
        "        42,  46,  49,  50,  54,  55,  56,  57,  61,  62,  64,  70,  72,\n",
        "        80,  84,  87,  88,  90, 100, 101, 102, 103, 105, 106, 107, 108,\n",
        "       109, 110, 111, 113, 114, 115, 117, 119, 120, 124, 126, 128, 134,\n",
        "       135, 137, 138, 139, 140, 141, 142, 145, 149, 151, 154, 156, 158,\n",
        "       159, 162, 165, 167, 168, 170, 171, 173, 176, 177, 178, 179, 182,\n",
        "       183, 185, 186, 188, 190, 191, 192, 193, 194, 196, 198, 200, 201,\n",
        "       203, 206, 208, 211, 212, 216, 218, 219, 224, 225, 226, 227, 231,\n",
        "       238, 239, 241, 243, 245, 246, 247, 251, 252, 253, 254, 259, 260,\n",
        "       261, 263, 264, 265, 266, 275, 280, 281, 283, 284, 287, 288, 291,\n",
        "       292, 293, 295, 296, 297, 298, 300, 301, 306, 307, 316, 317, 318,\n",
        "       319, 320, 322, 326, 329, 330, 331, 332, 333, 337, 339, 340, 341,\n",
        "       342, 344, 346, 347, 348, 352, 353, 355, 357, 361, 362, 363, 366,\n",
        "       368, 369, 371, 372, 373, 374, 378, 381, 383, 384, 386, 387, 389,\n",
        "       391, 393, 394, 395, 398, 399, 404, 405, 408, 411, 412, 418, 426,\n",
        "       433, 435, 441, 443, 444, 445, 446, 447, 449, 450, 451, 454, 455,\n",
        "       456, 457, 458, 460, 467, 470, 480, 482, 486, 488, 489, 490, 491,\n",
        "       494, 496, 498, 501, 502, 504, 506, 507, 511, 513, 514, 515, 516,\n",
        "       519, 522, 525, 526, 528, 530, 533, 534, 535, 542, 544, 547, 548,\n",
        "       551, 553, 554, 556, 557, 558, 559, 565, 567, 568, 569, 570, 571,\n",
        "       573, 574, 577, 580, 581, 582, 583, 584, 585, 586, 587, 592, 594,\n",
        "       596, 597, 598, 604, 605, 606, 608, 609, 611, 613, 614, 615, 617,\n",
        "       618, 619, 620, 623, 625, 626, 627, 628, 631, 632, 633, 641, 647,\n",
        "       649, 650, 652, 654, 658, 662, 663, 665, 666, 668, 681, 682, 685,\n",
        "       692, 708, 710, 716, 719, 749, 755, 757, 758, 760, 761, 771, 774]]\n",
        "'''\n",
        "tx_train_2 = tx_train_2[:, [  4,   6,   7,   9,  10,  11,  13,  15,  16,  18,  19,  21,  28,\n",
        "        42,  46,  49,  50,  54,  55,  56,  57,  61,  62,  63,  64,  70,\n",
        "        72,  75,  80,  81,  84,  87,  88,  90,  98,  99, 100, 101, 102,\n",
        "       103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119,\n",
        "       120, 124, 126, 128, 130, 134, 135, 136, 137, 138, 139, 140, 141,\n",
        "       142, 145, 149, 151, 154, 156, 158, 159, 162, 165, 167, 168, 170,\n",
        "       171, 173, 176, 177, 178, 179, 182, 183, 185, 186, 188, 190, 191,\n",
        "       192, 193, 194, 196, 198, 200, 201, 203, 205, 206, 208, 211, 212,\n",
        "       216, 218, 219, 224, 225, 226, 227, 231, 238, 239, 241, 243, 245,\n",
        "       246, 247, 251, 252, 253, 254, 255, 258, 259, 260, 261, 263, 264,\n",
        "       265, 266, 274, 275, 280, 281, 283, 284, 287, 288, 291, 292, 293,\n",
        "       295, 296, 297, 298, 300, 301, 302, 303, 306, 307, 312, 316, 317,\n",
        "       318, 319, 320, 322, 326, 329, 330, 331, 332, 333, 337, 339, 340,\n",
        "       341, 342, 344, 345, 346, 347, 348, 352, 353, 355, 357, 361, 362,\n",
        "       363, 366, 368, 369, 371, 372, 373, 374, 378, 381, 383, 384, 385,\n",
        "       386, 387, 389, 391, 393, 394, 395, 398, 399, 400, 404, 405, 408,\n",
        "       410, 411, 412, 418, 426, 433, 435, 441, 443, 444, 445, 446, 447,\n",
        "       449, 450, 451, 454, 455, 456, 457, 458, 460, 466, 467, 470, 472,\n",
        "       480, 482, 483, 484, 486, 488, 489, 490, 491, 493, 494, 496, 498,\n",
        "       501, 502, 503, 504, 506, 507, 511, 513, 514, 515, 516, 519, 522,\n",
        "       525, 526, 528, 530, 533, 534, 535, 542, 543, 544, 547, 548, 551,\n",
        "       553, 554, 556, 557, 558, 559, 562, 563, 565, 567, 568, 569, 570,\n",
        "       571, 573, 574, 577, 580, 581, 582, 583, 584, 585, 586, 587, 592,\n",
        "       594, 596, 597, 598, 604, 605, 606, 607, 608, 609, 611, 613, 614,\n",
        "       615, 617, 618, 619, 620, 623, 624, 625, 626, 627, 628, 631, 632,\n",
        "       633, 641, 647, 649, 650, 652, 654, 658, 662, 663, 665, 666, 668,\n",
        "       681, 682, 684, 685, 692, 694, 702, 708, 710, 716, 719, 726, 731,\n",
        "       734, 748, 749, 752, 755, 757, 758, 759, 760, 761, 771, 774]]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYtidhv11_H6",
        "outputId": "6c9033c0-1241-4ccf-df03-2b231d8f8b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tx_train_2.shape)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250000, 363)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyfGSxnTgt7M",
        "outputId": "e3e938ab-bfc5-46dc-ce9b-4c6b36e18fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "def train_model_pairwise(y, x):\n",
        "  w_init = np.zeros(x.shape[1])\n",
        "  lambda_ = 1e-5\n",
        "  return make_predictor(reg_logistic_regression_sgd(\n",
        "      y, x, lambda_, w_init, 5, 1000, 0.5)[0])\n",
        "\n",
        "_ = validation.cross_validation(y_train, tx_train_2, train_model_pairwise, 10, verbose=True)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ 10-fold cross validation results ------\n",
            "    Accuracy: avg 0.82856, max 0.83292, min 0.82388, stddev 0.002321\n",
            "    Fbeta score: avg 0.7392, max 0.74837, min 0.73026, stddev 0.0055279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tle2B4cOyFgT",
        "outputId": "dc487584-6397-4a1b-c570-b105b4a09aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "tune_lambda(y_train, tx_train_2, [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: 0.4238\n",
            "0.1: 0.7742\n",
            "0.01: 0.8155\n",
            "0.001: 0.8280\n",
            "0.0001: 0.8314\n",
            "1e-05: 0.8326\n",
            "1e-06: 0.8329\n",
            "1e-07: 0.8329\n",
            "1e-08: 0.8332\n",
            "1e-09: 0.8332\n",
            "1e-10: 0.8333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1e-10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x81VlDo4mZo"
      },
      "source": [
        "w, loss = lasso_logistic_regression_sgd(y_train, tx_train_2, .1, np.zeros(tx_train_2.shape[1]), 20, 200, .01)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZqgzwj5ZKx",
        "outputId": "e56e33a8-6e6e-4607-f18a-3f310f8b4862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "np.where(w > 1e-5)[0]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  4,   6,   7,   9,  10,  11,  13,  15,  16,  18,  19,  21,  28,\n",
              "        42,  46,  49,  50,  54,  55,  56,  57,  61,  62,  63,  64,  70,\n",
              "        72,  75,  80,  81,  84,  87,  88,  90,  98,  99, 100, 101, 102,\n",
              "       103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119,\n",
              "       120, 124, 126, 128, 130, 134, 135, 136, 137, 138, 139, 140, 141,\n",
              "       142, 145, 149, 151, 154, 156, 158, 159, 162, 165, 167, 168, 170,\n",
              "       171, 173, 176, 177, 178, 179, 182, 183, 185, 186, 188, 190, 191,\n",
              "       192, 193, 194, 196, 198, 200, 201, 203, 205, 206, 208, 211, 212,\n",
              "       216, 218, 219, 224, 225, 226, 227, 231, 238, 239, 241, 243, 245,\n",
              "       246, 247, 251, 252, 253, 254, 255, 258, 259, 260, 261, 263, 264,\n",
              "       265, 266, 274, 275, 280, 281, 283, 284, 287, 288, 291, 292, 293,\n",
              "       295, 296, 297, 298, 300, 301, 302, 303, 306, 307, 312, 316, 317,\n",
              "       318, 319, 320, 322, 326, 329, 330, 331, 332, 333, 337, 339, 340,\n",
              "       341, 342, 344, 345, 346, 347, 348, 352, 353, 355, 357, 361, 362,\n",
              "       363, 366, 368, 369, 371, 372, 373, 374, 378, 381, 383, 384, 385,\n",
              "       386, 387, 389, 391, 393, 394, 395, 398, 399, 400, 404, 405, 408,\n",
              "       410, 411, 412, 418, 426, 433, 435, 441, 443, 444, 445, 446, 447,\n",
              "       449, 450, 451, 454, 455, 456, 457, 458, 460, 466, 467, 470, 472,\n",
              "       480, 482, 483, 484, 486, 488, 489, 490, 491, 493, 494, 496, 498,\n",
              "       501, 502, 503, 504, 506, 507, 511, 513, 514, 515, 516, 519, 522,\n",
              "       525, 526, 528, 530, 533, 534, 535, 542, 543, 544, 547, 548, 551,\n",
              "       553, 554, 556, 557, 558, 559, 562, 563, 565, 567, 568, 569, 570,\n",
              "       571, 573, 574, 577, 580, 581, 582, 583, 584, 585, 586, 587, 592,\n",
              "       594, 596, 597, 598, 604, 605, 606, 607, 608, 609, 611, 613, 614,\n",
              "       615, 617, 618, 619, 620, 623, 624, 625, 626, 627, 628, 631, 632,\n",
              "       633, 641, 647, 649, 650, 652, 654, 658, 662, 663, 665, 666, 668,\n",
              "       681, 682, 684, 685, 692, 694, 702, 708, 710, 716, 719, 726, 731,\n",
              "       734, 748, 749, 752, 755, 757, 758, 759, 760, 761, 771, 774])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Mc1JD4iTGs"
      },
      "source": [
        "def create_submission(x_train, y_train, x_test, ids, train_model, file_name):\n",
        "  predict = train_model(y_train, x_train)\n",
        "  labels_train = predict(x_train)\n",
        "  train_acc = metrics.accuracy(y_train, labels_train) * 100\n",
        "  full_file_name = f'{file_name}.csv'\n",
        "  if input(f'Train accuracy is {train_acc:.3} %. \\n\\\n",
        "Do you want to continue and create submission `{full_file_name}`? [y/N]').strip().upper() == 'Y':\n",
        "    labels = predict(x_test)\n",
        "    labels = labels * 2 - 1\n",
        "    data_io.create_csv_submission(ids, labels, full_file_name)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMOZXBMYsKyA",
        "outputId": "fd1556a1-310c-4549-ed57-92422b009830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tx_test = transformation_pipeline_median_selected_pairwise(x_test)\n",
        "tx_test = tx_test[:, [  4,   6,   7,   9,  10,  11,  13,  15,  16,  18,  19,  21,  28,\n",
        "        42,  46,  49,  50,  54,  55,  56,  57,  61,  62,  63,  64,  70,\n",
        "        72,  75,  80,  81,  84,  87,  88,  90,  98,  99, 100, 101, 102,\n",
        "       103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119,\n",
        "       120, 124, 126, 128, 130, 134, 135, 136, 137, 138, 139, 140, 141,\n",
        "       142, 145, 149, 151, 154, 156, 158, 159, 162, 165, 167, 168, 170,\n",
        "       171, 173, 176, 177, 178, 179, 182, 183, 185, 186, 188, 190, 191,\n",
        "       192, 193, 194, 196, 198, 200, 201, 203, 205, 206, 208, 211, 212,\n",
        "       216, 218, 219, 224, 225, 226, 227, 231, 238, 239, 241, 243, 245,\n",
        "       246, 247, 251, 252, 253, 254, 255, 258, 259, 260, 261, 263, 264,\n",
        "       265, 266, 274, 275, 280, 281, 283, 284, 287, 288, 291, 292, 293,\n",
        "       295, 296, 297, 298, 300, 301, 302, 303, 306, 307, 312, 316, 317,\n",
        "       318, 319, 320, 322, 326, 329, 330, 331, 332, 333, 337, 339, 340,\n",
        "       341, 342, 344, 345, 346, 347, 348, 352, 353, 355, 357, 361, 362,\n",
        "       363, 366, 368, 369, 371, 372, 373, 374, 378, 381, 383, 384, 385,\n",
        "       386, 387, 389, 391, 393, 394, 395, 398, 399, 400, 404, 405, 408,\n",
        "       410, 411, 412, 418, 426, 433, 435, 441, 443, 444, 445, 446, 447,\n",
        "       449, 450, 451, 454, 455, 456, 457, 458, 460, 466, 467, 470, 472,\n",
        "       480, 482, 483, 484, 486, 488, 489, 490, 491, 493, 494, 496, 498,\n",
        "       501, 502, 503, 504, 506, 507, 511, 513, 514, 515, 516, 519, 522,\n",
        "       525, 526, 528, 530, 533, 534, 535, 542, 543, 544, 547, 548, 551,\n",
        "       553, 554, 556, 557, 558, 559, 562, 563, 565, 567, 568, 569, 570,\n",
        "       571, 573, 574, 577, 580, 581, 582, 583, 584, 585, 586, 587, 592,\n",
        "       594, 596, 597, 598, 604, 605, 606, 607, 608, 609, 611, 613, 614,\n",
        "       615, 617, 618, 619, 620, 623, 624, 625, 626, 627, 628, 631, 632,\n",
        "       633, 641, 647, 649, 650, 652, 654, 658, 662, 663, 665, 666, 668,\n",
        "       681, 682, 684, 685, 692, 694, 702, 708, 710, 716, 719, 726, 731,\n",
        "       734, 748, 749, 752, 755, 757, 758, 759, 760, 761, 771, 774]]\n",
        "\n",
        "lambda_ = 1e-8\n",
        "train_model = lambda y_, x_: make_predictor(reg_logistic_regression_sgd(\n",
        "    y_, x_, lambda_, np.zeros(x_.shape[1]), 20, 1000, 0.5,\n",
        ")[0])\n",
        "\n",
        "create_submission(\n",
        "    tx_train_2, y_train, \n",
        "    tx_test, \n",
        "    ids_test, train_model, '832accSub')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy is 83.2 %. \n",
            "Do you want to continue and create submission `832accSub.csv`? [y/N]y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}